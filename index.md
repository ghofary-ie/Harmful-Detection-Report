# Harmful Content Detection Pipeline: From Data to Insights

This project demonstrates a complete workflow for detecting harmful content on social media using machine learning models combined with human review.

The dataset used originates from [Kaggle.com](https://www.kaggle.com/) and is intended for research and educational purposes. While the dataset may contain publicly available social media content, all personally identifiable information has been anonymized to ensure privacy and compliance with ethical data handling standards.

The goal is to build and evaluate an effective pipeline that:

- Loads and preprocesses raw comment data
- Applies transformer-based toxicity models (e.g., Detoxify, HuggingFace)
- Integrates human review labels to validate and improve model predictions
- Identifies false positives and false negatives for error analysis
- Provides clear evaluation metrics and visualizations to understand model performance
- Highlights challenges and considerations in real-world harmful content detection

This practical approach reflects real-world Trust & Safety workflows, where automated tools assist human moderators in maintaining safer online communities.

**Note on Data Usage:**  
All efforts are made to handle the data responsibly, respecting user privacy and platform policies. Sensitive content is treated with care, and this project is intended solely for educational and portfolio purposes.
